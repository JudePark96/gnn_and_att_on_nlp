training: 
    seed: 11747
    dataset: "Multi30k"  # Multi30k or ISWLT
    model: "transformer"  # gru**2, gru_attn**2, transformer, gcn_gru
    reverse: False
    batch_size: 128
    encoder_embed_dim: 250
    decoder_embed_dim: 250
    encoder_hidden_dim: 256
    decoder_hidden_dim: 256
    encoder_heads: 8
    decoder_heads: 8
    encoder_pf_dim: 512
    decoder_pf_dim: 512
    encoder_dropout: 0.2
    decoder_dropout: 0.2
    num_layers: 3
    num_epochs: 1
    grad_clip: 1
    max_len: 150
    lr: 0.0005
    lr_decay_ratio: 0.9
    id: 1
    patience: 5