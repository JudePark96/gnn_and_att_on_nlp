training:
  batch_size: 128
  dataset: Multi30k
  decoder_dropout: 0.5
  decoder_embed_dim: 300
  decoder_hidden_dim: 600
  encoder_dropout: 0.5
  encoder_embed_dim: 300
  encoder_hidden_dim: 600
  grad_clip: 1
  id: 3
  lr: 0.001
  lr_decay_ratio: 0.98
  model: gru_attn**2
  num_epochs: 20
  num_layers: 2
  patience: 5
  reverse: true
  seed: 11747
