{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing and Visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<pad>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test performances\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_vocab(vocab):\n",
    "    return dict([(v, k) for k,v in vocab.items()])\n",
    "\n",
    "def validate_vocab(d):\n",
    "    print(f\"one to one mapping: {bool(len(d) == len(set([v for _, v in d.items()])))}\")\n",
    "    print(len(d), len(set([v for _, v in d.items()])))\n",
    "    \n",
    "def set_util_maps(itos):\n",
    "    itos[0] = '<unk>'\n",
    "    itos[1] = '<pad>'\n",
    "    itos[2] = '<sos>'\n",
    "    itos[3] = '<eos>'\n",
    "    return itos\n",
    "\n",
    "def batched_data_to_list(src, tgt, pred_tgts):\n",
    "    \"\"\" src, tgt, pred_tgts have format:\n",
    "    [tensor(src_len, batch size), ...]\n",
    "    \n",
    "    return [[int0, int1, int2,...],...]\n",
    "    \"\"\"\n",
    "    src_, tgt_, pred_tgts_ = [], [], []\n",
    "    \n",
    "    for batch in src:\n",
    "        src_.extend([datum.tolist() for datum in batch.transpose(1,0)])\n",
    "    \n",
    "    for batch in tgt:\n",
    "        tgt_.extend([datum.tolist() for datum in batch.transpose(1,0)])\n",
    "        \n",
    "    for batch in pred_tgts:\n",
    "        pred_tgts_.extend([datum.tolist() for datum in batch.argmax(2).transpose(1,0)])\n",
    "        \n",
    "    return src_, tgt_, pred_tgts_\n",
    "\n",
    "\n",
    "def ints_to_sentences(sent, vocab):\n",
    "    \"\"\"sent is a sequence of ints\"\"\"\n",
    "    return [vocab[w] if w in vocab else \"<unk>\" for w in sent]\n",
    "\n",
    "def clip_sentence(sent):\n",
    "    \"\"\" sent: list[str] \"\"\"\n",
    "    # remove initial <sos>\n",
    "    sent = sent[1:]\n",
    "    \n",
    "    # stop when first \"<eos>\" generated\n",
    "    sent_ = []\n",
    "    for w in sent:\n",
    "        if w == '<eos>':\n",
    "            return sent_\n",
    "        sent_.append(w)\n",
    "    return sent_\n",
    "\n",
    "def postprocess(src, tgt, pred_tgts, src_itos, tgt_itos):\n",
    "    src, tgt, pred_tgts = batched_data_to_list(src, tgt, pred_tgts)\n",
    "    src = list(map(lambda sent: ints_to_sentences(sent, src_itos), src))\n",
    "    tgt = list(map(lambda sent: ints_to_sentences(sent, tgt_itos), tgt))\n",
    "    pred_tgts = list(map(lambda sent: ints_to_sentences(sent, tgt_itos), pred_tgts))\n",
    "    \n",
    "    src = list(map(clip_sentence, src))\n",
    "    tgt = list(map(clip_sentence, tgt))\n",
    "    pred_tgts = list(map(clip_sentence, pred_tgts))\n",
    "    return src, tgt, pred_tgts\n",
    "\n",
    "def bleu_score_wrapper(tgt, pred_tgts):\n",
    "    \"\"\" convert format of tgt to appropriate format \"\"\"\n",
    "    tgt = [[t] for t in tgt]\n",
    "    return bleu_score(pred_tgts, tgt)\n",
    "\n",
    "def write_translations(sents, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for sent in sents:\n",
    "            f.write(\" \".join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 2.373911067843437\n"
     ]
    }
   ],
   "source": [
    "# Multi30k-gru**2-5\n",
    "payload = torch.load(\"for-analysis/Multi30k-gru**2-5/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gru**2.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 7.8253477811813354\n"
     ]
    }
   ],
   "source": [
    "# Multi30k-gcn_gru-1\n",
    "payload = torch.load(\"for-analysis/Multi30k-gcn_gru-1/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gcn_gru.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 22.964130342006683\n"
     ]
    }
   ],
   "source": [
    "# Multi30k-gcngru_gru-1\n",
    "payload = torch.load(\"for-analysis/Multi30k-gcngru_gru-1/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gcngru_gru.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'attns', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 16.638437879309034\n"
     ]
    }
   ],
   "source": [
    "# Multi30k-gcnattn_gru-1\n",
    "payload = torch.load(\"for-analysis/Multi30k-gcnattn_gru-1/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gcnattn_gru.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'attns', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 29.867154359817505\n"
     ]
    }
   ],
   "source": [
    "# gru_attn**2\n",
    "payload = torch.load(\"for-analysis/Multi30k-gru_attn**2-3/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "attns = payload['attns']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gru_attn.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'attns', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n",
      "Bleu score: 29.064443707466125\n"
     ]
    }
   ],
   "source": [
    "# Multi30k-gcngruattn_gru-1\n",
    "payload = torch.load(\"for-analysis/Multi30k-gcngruattn_gru-1/payload.pt\")\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "attns = payload['attns']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']  # stoi\n",
    "tgt_vocab = payload['TGT_vocab']  # stoi\n",
    "src_itos = set_util_maps(reverse_vocab(src_vocab))\n",
    "tgt_itos = set_util_maps(reverse_vocab(tgt_vocab))\n",
    "\n",
    "# compute bleu score\n",
    "src, tgt, pred_tgts = postprocess(src, tgt, pred_tgts, src_itos, tgt_itos)\n",
    "write_translations(pred_tgts, \"for-analysis/output_translations/gcngruattn_gru.eng\")\n",
    "print(f\"Bleu score: {bleu_score_wrapper(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_translations(tgt, \"for-analysis/output_translations/ref.eng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separately deal with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred_tgts', 'attns', 'src', 'tgt', 'SRC_vocab', 'TGT_vocab'])\n"
     ]
    }
   ],
   "source": [
    "# transformer\n",
    "payload = torch.load(\"for-analysis/Multi30k-transformer-100/payload.pt\", map_location=torch.device('cpu'))\n",
    "print(payload.keys())\n",
    "pred_tgts = payload['pred_tgts']\n",
    "attns = payload['attns']\n",
    "src = payload['src']\n",
    "tgt = payload['tgt']\n",
    "src_vocab = payload['SRC_vocab']\n",
    "tgt_vocab = payload['TGT_vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score: 36.49856947437553\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bleu score: {bleu_score(pred_tgts, tgt)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 types of models:\n",
    "* seq2seq -  don't need to worry about it because teacher forceing was turned off during testing\n",
    "* seq2seq with attention - don't need to worry either...teacher forcing was turned off during testing\n",
    "* transformer - worry about it.\n",
    "\n",
    "Each would need a version of translate operation. So we need to load and run all of them to generate test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, random, math, time, yaml, sys, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.datasets import TranslationDataset, Multi30k, IWSLT\n",
    "from torchtext.data import Field, BucketIterator, RawField, Dataset\n",
    "from moduleloader import ModuleLoader\n",
    "from models.gcn import GCNLayer\n",
    "from src.utils import set_seed, tokenize_de, tokenize_en, batch_graph, \\\n",
    "get_sentence_lengths, counter2array, ensure_path_exist, \\\n",
    "print_status, learning_rate_decay, count_parameters\n",
    "from src.early_stopping import EarlyStopping\n",
    "from src.logging import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n",
    "# config_file = 'for-analysis/Multi30k-transformer-100/config.yaml'\n",
    "# loader = ModuleLoader(config_file)\n",
    "# config = loader.config\n",
    "# train_data = loader.train_data\n",
    "# valid_data = loader.valid_data\n",
    "# test_data = loader.test_data\n",
    "# train_iterator = loader.train_iterator\n",
    "# valid_iterator = loader.valid_iterator\n",
    "# test_iterator = loader.test_iterator\n",
    "# SRC = loader.SRC\n",
    "# TGT = loader.TGT\n",
    "# GRH = loader.GRH\n",
    "# SRC_PAD_IDX = loader.SRC_PAD_IDX\n",
    "# TGT_PAD_IDX = loader.TGT_PAD_IDX\n",
    "# enc = loader.enc\n",
    "# dec = loader.dec\n",
    "# model = loader.model\n",
    "# train_epoch = loader.train_epoch\n",
    "# evaluate = loader.evaluate\n",
    "# criterion = loader.criterion\n",
    "# device = loader.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz",
   "language": "python",
   "name": "visualization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
