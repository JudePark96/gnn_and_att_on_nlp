(pytorch_p36) sh-4.2$ python3 train.py 20ng
Using onehot features?  True
[2020/4/17 15:00:21] Epoch: 1, train_loss= 3.00457, train_acc= 0.04930, val_loss= 2.99324, val_acc= 0.27915, time= 30.67479
[2020/4/17 15:00:49] Epoch: 2, train_loss= 2.97214, train_acc= 0.26586, val_loss= 2.99054, val_acc= 0.54770, time= 28.20998
[2020/4/17 15:01:18] Epoch: 3, train_loss= 2.94508, train_acc= 0.55903, val_loss= 2.98789, val_acc= 0.67845, time= 29.42358
[2020/4/17 15:01:47] Epoch: 4, train_loss= 2.91906, train_acc= 0.71931, val_loss= 2.98517, val_acc= 0.71643, time= 28.39977
[2020/4/17 15:02:16] Epoch: 5, train_loss= 2.89269, train_acc= 0.77195, val_loss= 2.98233, val_acc= 0.73763, time= 28.97300
[2020/4/17 15:02:45] Epoch: 6, train_loss= 2.86553, train_acc= 0.79984, val_loss= 2.97939, val_acc= 0.76413, time= 29.17516
[2020/4/17 15:03:14] Epoch: 7, train_loss= 2.83767, train_acc= 0.82931, val_loss= 2.97640, val_acc= 0.80124, time= 29.01316
[2020/4/17 15:03:43] Epoch: 8, train_loss= 2.80953, train_acc= 0.85494, val_loss= 2.97343, val_acc= 0.82244, time= 29.13958
[2020/4/17 15:04:12] Epoch: 9, train_loss= 2.78167, train_acc= 0.87812, val_loss= 2.97055, val_acc= 0.84099, time= 29.06067
[2020/4/17 15:04:41] Epoch: 10, train_loss= 2.75477, train_acc= 0.89521, val_loss= 2.96785, val_acc= 0.85159, time= 29.09646
[2020/4/17 15:05:10] Epoch: 11, train_loss= 2.72952, train_acc= 0.90925, val_loss= 2.96539, val_acc= 0.86219, time= 29.38474
[2020/4/17 15:05:33] Epoch: 12, train_loss= 2.70639, train_acc= 0.91514, val_loss= 2.96317, val_acc= 0.87191, time= 22.83630
[2020/4/17 15:05:53] Epoch: 13, train_loss= 2.68548, train_acc= 0.92143, val_loss= 2.96116, val_acc= 0.87809, time= 19.75346
[2020/4/17 15:06:13] Epoch: 14, train_loss= 2.66660, train_acc= 0.92605, val_loss= 2.95935, val_acc= 0.88339, time= 19.88907
[2020/4/17 15:06:33] Epoch: 15, train_loss= 2.64953, train_acc= 0.92919, val_loss= 2.95772, val_acc= 0.88693, time= 19.97119
[2020/4/17 15:06:53] Epoch: 16, train_loss= 2.63433, train_acc= 0.93174, val_loss= 2.95631, val_acc= 0.89046, time= 20.00562
[2020/4/17 15:07:13] Epoch: 17, train_loss= 2.62108, train_acc= 0.93282, val_loss= 2.95510, val_acc= 0.88958, time= 20.07888
[2020/4/17 15:07:33] Epoch: 18, train_loss= 2.60965, train_acc= 0.93390, val_loss= 2.95406, val_acc= 0.88869, time= 19.94600
[2020/4/17 15:07:53] Epoch: 19, train_loss= 2.59971, train_acc= 0.93577, val_loss= 2.95317, val_acc= 0.89223, time= 19.91583
[2020/4/17 15:08:14] Epoch: 20, train_loss= 2.59098, train_acc= 0.93881, val_loss= 2.95239, val_acc= 0.89399, time= 20.67966
[2020/4/17 15:08:34] Epoch: 21, train_loss= 2.58328, train_acc= 0.94245, val_loss= 2.95169, val_acc= 0.89664, time= 20.83809
[2020/4/17 15:09:04] Epoch: 22, train_loss= 2.57648, train_acc= 0.94549, val_loss= 2.95106, val_acc= 0.89753, time= 29.15616
[2020/4/17 15:09:33] Epoch: 23, train_loss= 2.57047, train_acc= 0.94785, val_loss= 2.95050, val_acc= 0.89664, time= 29.08548
[2020/4/17 15:10:02] Epoch: 24, train_loss= 2.56517, train_acc= 0.94893, val_loss= 2.95001, val_acc= 0.89664, time= 29.15750
[2020/4/17 15:10:31] Epoch: 25, train_loss= 2.56048, train_acc= 0.95158, val_loss= 2.94958, val_acc= 0.90018, time= 29.24377
[2020/4/17 15:11:00] Epoch: 26, train_loss= 2.55630, train_acc= 0.95374, val_loss= 2.94922, val_acc= 0.90018, time= 29.38566
[2020/4/17 15:11:30] Epoch: 27, train_loss= 2.55257, train_acc= 0.95522, val_loss= 2.94891, val_acc= 0.90018, time= 29.28304
[2020/4/17 15:11:59] Epoch: 28, train_loss= 2.54922, train_acc= 0.95698, val_loss= 2.94864, val_acc= 0.90194, time= 29.08661
[2020/4/17 15:12:28] Epoch: 29, train_loss= 2.54615, train_acc= 0.95846, val_loss= 2.94839, val_acc= 0.90459, time= 29.46103
[2020/4/17 15:12:52] Epoch: 30, train_loss= 2.54339, train_acc= 0.95944, val_loss= 2.94817, val_acc= 0.90371, time= 23.26144
[2020/4/17 15:13:11] Epoch: 31, train_loss= 2.54091, train_acc= 0.96170, val_loss= 2.94797, val_acc= 0.90371, time= 19.95763
[2020/4/17 15:13:31] Epoch: 32, train_loss= 2.53863, train_acc= 0.96327, val_loss= 2.94780, val_acc= 0.90459, time= 20.01448
[2020/4/17 15:13:52] Epoch: 33, train_loss= 2.53653, train_acc= 0.96494, val_loss= 2.94764, val_acc= 0.90548, time= 20.04249
[2020/4/17 15:14:12] Epoch: 34, train_loss= 2.53461, train_acc= 0.96779, val_loss= 2.94749, val_acc= 0.90459, time= 20.67419
[2020/4/17 15:14:32] Epoch: 35, train_loss= 2.53287, train_acc= 0.96955, val_loss= 2.94736, val_acc= 0.90724, time= 19.86669
[2020/4/17 15:14:52] Epoch: 36, train_loss= 2.53126, train_acc= 0.97132, val_loss= 2.94724, val_acc= 0.90901, time= 20.04382
[2020/4/17 15:15:12] Epoch: 37, train_loss= 2.52977, train_acc= 0.97211, val_loss= 2.94713, val_acc= 0.90989, time= 19.73423
[2020/4/17 15:15:31] Epoch: 38, train_loss= 2.52837, train_acc= 0.97388, val_loss= 2.94703, val_acc= 0.91078, time= 19.60040
[2020/4/17 15:15:51] Epoch: 39, train_loss= 2.52707, train_acc= 0.97525, val_loss= 2.94694, val_acc= 0.91078, time= 19.74464
[2020/4/17 15:16:11] Epoch: 40, train_loss= 2.52586, train_acc= 0.97613, val_loss= 2.94686, val_acc= 0.91166, time= 19.81467
[2020/4/17 15:16:31] Epoch: 41, train_loss= 2.52474, train_acc= 0.97790, val_loss= 2.94677, val_acc= 0.91254, time= 19.86444
[2020/4/17 15:16:51] Epoch: 42, train_loss= 2.52370, train_acc= 0.97918, val_loss= 2.94670, val_acc= 0.91696, time= 19.85441
[2020/4/17 15:17:11] Epoch: 43, train_loss= 2.52272, train_acc= 0.98026, val_loss= 2.94663, val_acc= 0.91696, time= 20.55513
[2020/4/17 15:17:31] Epoch: 44, train_loss= 2.52180, train_acc= 0.98124, val_loss= 2.94658, val_acc= 0.91696, time= 19.85164
[2020/4/17 15:17:51] Epoch: 45, train_loss= 2.52094, train_acc= 0.98203, val_loss= 2.94653, val_acc= 0.91784, time= 19.90183
[2020/4/17 15:18:11] Epoch: 46, train_loss= 2.52012, train_acc= 0.98350, val_loss= 2.94649, val_acc= 0.91784, time= 19.92321
[2020/4/17 15:18:31] Epoch: 47, train_loss= 2.51935, train_acc= 0.98478, val_loss= 2.94646, val_acc= 0.91961, time= 20.02981
[2020/4/17 15:18:51] Epoch: 48, train_loss= 2.51863, train_acc= 0.98615, val_loss= 2.94641, val_acc= 0.91961, time= 19.90172
[2020/4/17 15:19:11] Epoch: 49, train_loss= 2.51794, train_acc= 0.98694, val_loss= 2.94638, val_acc= 0.91961, time= 19.88893
[2020/4/17 15:19:31] Epoch: 50, train_loss= 2.51730, train_acc= 0.98743, val_loss= 2.94634, val_acc= 0.91873, time= 19.92964
[2020/4/17 15:19:51] Epoch: 51, train_loss= 2.51669, train_acc= 0.98792, val_loss= 2.94631, val_acc= 0.91873, time= 19.92703
[2020/4/17 15:20:11] Epoch: 52, train_loss= 2.51611, train_acc= 0.98841, val_loss= 2.94629, val_acc= 0.91873, time= 20.81584
[2020/4/17 15:20:31] Epoch: 53, train_loss= 2.51556, train_acc= 0.98920, val_loss= 2.94627, val_acc= 0.91873, time= 19.88387
[2020/4/17 15:20:51] Epoch: 54, train_loss= 2.51504, train_acc= 0.98949, val_loss= 2.94625, val_acc= 0.91961, time= 19.84129
[2020/4/17 15:21:11] Epoch: 55, train_loss= 2.51455, train_acc= 0.99018, val_loss= 2.94622, val_acc= 0.91873, time= 19.88065
[2020/4/17 15:21:31] Epoch: 56, train_loss= 2.51408, train_acc= 0.99057, val_loss= 2.94620, val_acc= 0.91873, time= 19.86433
[2020/4/17 15:21:51] Epoch: 57, train_loss= 2.51364, train_acc= 0.99116, val_loss= 2.94618, val_acc= 0.91961, time= 19.90548
[2020/4/17 15:22:11] Epoch: 58, train_loss= 2.51321, train_acc= 0.99214, val_loss= 2.94616, val_acc= 0.92049, time= 19.91174
[2020/4/17 15:22:31] Epoch: 59, train_loss= 2.51281, train_acc= 0.99254, val_loss= 2.94615, val_acc= 0.92138, time= 19.89940
[2020/4/17 15:22:51] Epoch: 60, train_loss= 2.51243, train_acc= 0.99293, val_loss= 2.94614, val_acc= 0.92138, time= 19.86758
[2020/4/17 15:23:11] Epoch: 61, train_loss= 2.51206, train_acc= 0.99332, val_loss= 2.94613, val_acc= 0.92049, time= 20.95776
[2020/4/17 15:23:31] Epoch: 62, train_loss= 2.51172, train_acc= 0.99362, val_loss= 2.94612, val_acc= 0.92138, time= 19.98403
[2020/4/17 15:23:52] Epoch: 63, train_loss= 2.51138, train_acc= 0.99430, val_loss= 2.94610, val_acc= 0.92226, time= 20.04224
[2020/4/17 15:24:12] Epoch: 64, train_loss= 2.51107, train_acc= 0.99450, val_loss= 2.94609, val_acc= 0.92226, time= 20.01339
[2020/4/17 15:24:31] Epoch: 65, train_loss= 2.51077, train_acc= 0.99479, val_loss= 2.94609, val_acc= 0.92138, time= 19.88727
[2020/4/17 15:24:51] Epoch: 66, train_loss= 2.51048, train_acc= 0.99509, val_loss= 2.94608, val_acc= 0.92138, time= 19.84127
[2020/4/17 15:25:11] Epoch: 67, train_loss= 2.51020, train_acc= 0.99519, val_loss= 2.94608, val_acc= 0.92138, time= 19.86984
[2020/4/17 15:25:31] Epoch: 68, train_loss= 2.50994, train_acc= 0.99538, val_loss= 2.94607, val_acc= 0.92049, time= 19.57786
[2020/4/17 15:25:50] Epoch: 69, train_loss= 2.50969, train_acc= 0.99597, val_loss= 2.94606, val_acc= 0.92138, time= 19.66148
[2020/4/17 15:26:11] Epoch: 70, train_loss= 2.50944, train_acc= 0.99646, val_loss= 2.94606, val_acc= 0.92138, time= 20.88865
[2020/4/17 15:26:31] Epoch: 71, train_loss= 2.50921, train_acc= 0.99656, val_loss= 2.94605, val_acc= 0.92226, time= 19.88602
[2020/4/17 15:26:51] Epoch: 72, train_loss= 2.50899, train_acc= 0.99696, val_loss= 2.94604, val_acc= 0.92314, time= 19.91430
[2020/4/17 15:27:11] Epoch: 73, train_loss= 2.50877, train_acc= 0.99754, val_loss= 2.94604, val_acc= 0.92314, time= 19.90386
[2020/4/17 15:27:31] Epoch: 74, train_loss= 2.50857, train_acc= 0.99745, val_loss= 2.94604, val_acc= 0.92314, time= 19.97144
[2020/4/17 15:27:51] Epoch: 75, train_loss= 2.50837, train_acc= 0.99735, val_loss= 2.94604, val_acc= 0.92314, time= 19.98005
[2020/4/17 15:28:11] Epoch: 76, train_loss= 2.50818, train_acc= 0.99735, val_loss= 2.94604, val_acc= 0.92314, time= 19.96272
[2020/4/17 15:28:31] Epoch: 77, train_loss= 2.50800, train_acc= 0.99754, val_loss= 2.94603, val_acc= 0.92314, time= 19.93424
[2020/4/17 15:28:51] Epoch: 78, train_loss= 2.50782, train_acc= 0.99774, val_loss= 2.94603, val_acc= 0.92403, time= 19.87721
[2020/4/17 15:29:12] Epoch: 79, train_loss= 2.50765, train_acc= 0.99774, val_loss= 2.94603, val_acc= 0.92403, time= 21.02380
[2020/4/17 15:29:32] Epoch: 80, train_loss= 2.50749, train_acc= 0.99774, val_loss= 2.94603, val_acc= 0.92580, time= 19.94827
[2020/4/17 15:29:52] Epoch: 81, train_loss= 2.50733, train_acc= 0.99784, val_loss= 2.94603, val_acc= 0.92580, time= 19.88355
[2020/4/17 15:30:11] Epoch: 82, train_loss= 2.50718, train_acc= 0.99774, val_loss= 2.94603, val_acc= 0.92668, time= 19.90307
[2020/4/17 15:30:31] Epoch: 83, train_loss= 2.50704, train_acc= 0.99804, val_loss= 2.94603, val_acc= 0.92668, time= 19.90761
[2020/4/17 15:30:51] Epoch: 84, train_loss= 2.50690, train_acc= 0.99804, val_loss= 2.94603, val_acc= 0.92668, time= 19.89774
[2020/4/17 15:31:11] Epoch: 85, train_loss= 2.50676, train_acc= 0.99813, val_loss= 2.94603, val_acc= 0.92668, time= 19.92821
[2020/4/17 15:31:31] Epoch: 86, train_loss= 2.50663, train_acc= 0.99823, val_loss= 2.94603, val_acc= 0.92668, time= 19.97353
[2020/4/17 15:31:51] Epoch: 87, train_loss= 2.50651, train_acc= 0.99853, val_loss= 2.94603, val_acc= 0.92668, time= 19.93319
[2020/4/17 15:32:12] Epoch: 88, train_loss= 2.50638, train_acc= 0.99853, val_loss= 2.94603, val_acc= 0.92668, time= 20.70580
[2020/4/17 15:32:32] Epoch: 89, train_loss= 2.50627, train_acc= 0.99853, val_loss= 2.94603, val_acc= 0.92668, time= 19.93905
[2020/4/17 15:32:32] Early stopping...
[2020/4/17 15:32:32] Optimization Finished!
[2020/4/17 15:32:38] Test set results: 
[2020/4/17 15:32:38]     loss= 2.69271, accuracy= 0.86046, time= 6.48547
[2020/4/17 15:32:38] Test Precision, Recall and F1-Score...
[2020/4/17 15:32:38]               precision    recall  f1-score   support
[2020/4/17 15:32:38] 
[2020/4/17 15:32:38]            0     0.8785    0.9447    0.9104       398
[2020/4/17 15:32:38]            1     0.7383    0.8123    0.7736       389
[2020/4/17 15:32:38]            2     0.8067    0.8667    0.8356       390
[2020/4/17 15:32:38]            3     0.7167    0.6853    0.7006       251
[2020/4/17 15:32:38]            4     0.8405    0.6968    0.7619       310
[2020/4/17 15:32:38]            5     0.9917    0.9521    0.9715       376
[2020/4/17 15:32:38]            6     0.9446    0.9040    0.9239       396
[2020/4/17 15:32:38]            7     0.8146    0.7939    0.8041       393
[2020/4/17 15:32:38]            8     0.8355    0.7975    0.8161       395
[2020/4/17 15:32:38]            9     0.8125    0.8929    0.8508       364
[2020/4/17 15:32:38]           10     0.8346    0.8390    0.8368       385
[2020/4/17 15:32:38]           11     0.9550    0.9598    0.9574       398
[2020/4/17 15:32:38]           12     0.7950    0.7284    0.7603       394
[2020/4/17 15:32:38]           13     0.8972    0.8813    0.8892       396
[2020/4/17 15:32:38]           14     0.9158    0.9343    0.9250       396
[2020/4/17 15:32:38]           15     0.8630    0.7900    0.8249       319
[2020/4/17 15:32:38]           16     0.9337    0.9572    0.9453       397
[2020/4/17 15:32:38]           17     0.9045    0.9137    0.9091       394
[2020/4/17 15:32:38]           18     0.7183    0.7806    0.7482       392
[2020/4/17 15:32:38]           19     0.9747    0.9674    0.9711       399
[2020/4/17 15:32:38] 
[2020/4/17 15:32:38]    micro avg     0.8605    0.8605    0.8605      7532
[2020/4/17 15:32:38]    macro avg     0.8586    0.8549    0.8558      7532
[2020/4/17 15:32:38] weighted avg     0.8617    0.8605    0.8602      7532
[2020/4/17 15:32:38] 
[2020/4/17 15:32:38] Macro average Test Precision, Recall and F1-Score...
[2020/4/17 15:32:38] (0.8585746064879535, 0.8548938164320543, 0.8557766078584388, None)
[2020/4/17 15:32:38] Micro average Test Precision, Recall and F1-Score...
[2020/4/17 15:32:38] (0.8604620286776421, 0.8604620286776421, 0.8604620286776421, None)
[2020/4/17 15:32:38] Embeddings:
Word_embeddings:44035
Train_doc_embeddings:10182
Test_doc_embeddings:7532
Word_embeddings::38] 
[[0.3554964  0.8667176  0.06568606 ... 0.6639219  0.5230969  0.47803146]
 [0.13077767 0.         0.29299104 ... 0.         0.10389546 0.00225209]
 [0.00536465 0.25094864 0.07671981 ... 0.14148417 0.18406437 0.        ]
 ...
 [0.21301736 0.         0.22897473 ... 0.         0.14177823 0.        ]
 [0.16194558 0.18900558 0.2096275  ... 0.         0.05430336 0.        ]
 [0.2679754  0.         0.04455776 ... 0.3360291  0.0083005  0.01829093]]